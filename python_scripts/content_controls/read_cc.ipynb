{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from docx import Document\n",
    "\n",
    "# Open the Word document\n",
    "doc = Document('/Users/senthil/Desktop/Senthil/myTesting/python_scripts/content_controls/TNFUK_03_ORJU-TS_C003.docx')\n",
    "\n",
    "# Iterate through the paragraphs in the document\n",
    "for para in doc.paragraphs:\n",
    "    # Check if the run is a content control\n",
    "    if para._element.tag.endswith('sdt'):\n",
    "        # Print the tag name of the content control\n",
    "        print(para._element.attrib['tag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from docx import Document\n",
    "\n",
    "# Open the Word document\n",
    "doc = Document('/Users/senthil/Desktop/Senthil/myTesting/python_scripts/content_controls/RL_00_ADCH_PRELIMS.docx')\n",
    "\n",
    "# Iterate through the paragraphs in the document\n",
    "for para in doc.paragraphs:\n",
    "    if 'sdt' in para._element.tag:\n",
    "        sdt = para._element\n",
    "        tag = None\n",
    "        for child in sdt:\n",
    "            if 'tag' in child.tag:\n",
    "                tag = child.attrib['val']\n",
    "                break\n",
    "        if tag:\n",
    "            print(\"Tag Name:\", tag)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FRONTMATTER\n",
      "Half_Title\n",
      "Book_Title\n",
      "Sub_Title\n",
      "Book_Author\n",
      "AUTHOR\n",
      "GIVENNAME\n",
      "SURNAME\n",
      "Imprint_Group\n",
      "Imprint\n",
      "Imprint\n",
      "Phrase\n",
      "Phrase\n",
      "Pub_Address\n",
      "Phrase\n",
      "URL\n",
      "Pub_Address\n",
      "Holder\n",
      "Legal_Notice\n",
      "para\n",
      "Legal_Notice\n",
      "para\n",
      "Legal_Notice\n",
      "para\n",
      "para\n",
      "Legal_Notice\n",
      "para\n",
      "Dedication\n",
      "para\n"
     ]
    }
   ],
   "source": [
    "from docx import Document\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "# Open the Word document\n",
    "doc = Document('/Users/senthil/Desktop/Senthil/myTesting/python_scripts/content_controls/RL_00_ADCH_PRELIMS.docx')\n",
    "\n",
    "# inline tag names\n",
    "inlineTags = ['TBLCIT','title','gt','gd','DAY','MONTH','YEAR','Department','Country','CITY','INSTITUTION','STATE','AFFLABEL','email','URL','fnlink','AFFCIT','SURNAME','GIVENNAME','suffix','forename','prefix','degrees','AUTHOR','CORCIT','on-behalf-of','Bubble','REFCIT','FIGCIT','inlineequation','token','link','inline','chartlabel','chartcaption','CORAUTHOR','phone','fax','Rec','ACC','Rev','term','def','Speaker','line','SECCIT','figlabel','figcaption','figsource','figpara','figsource_break','alttext','SUPPCIT','seelink','FMT_Sub','Date','volume','issue','doi','edition','Editedby','imagelabel','imagecaption','Imprint','see','seealso','KW','KeywordTitle','ChartCIT','copyright','publicationdate','fpage','lpage','BOXCIT','CHAPCIT','PARTCIT','SUPPData','SchemesCIT','MapCIT','PlatesCIT','PhotoCIT','ImageCIT','Chapter','photolabel','photocaption','plateslabel','platescaption','page','type','REFID','journaltitle','pages','pubmed','crossref','chapter-title','publisher','labeltext','uri','season','misc','comment','supp','isbn','editor','booktitle','loc','collab','schemeslabel','schemescaption','seelabel','alt-text','tblfnlink','tbllabel','tblcaption','Abbreviation','Ack','AFFS','BACKMATTER','BL','BODYMATTER','Box_BulletList','Box_Group','Box_Group1','Box_NumberedList','Box_UnorderedList','CHAPTERBACKMATTER','CHAPTERFRONTMATTER','Contributors','Corresp-Group','Dialogue','Example_BulletList','Example_Group','Example_NumberedList','Example_UnorderedList','Extract','Extract_BulletList','Extract_Group','Extract_NumberedList','Extract_UnorderedList','Floats','Forward','FRONTMATTER','funding_group','glossary','glossary_text','Imprint_Group','Index','Index_Group','List_of_ILL','Math_BulletList','Math_Group','Math_NumberedList','Math_UnorderedList','NL','Part','Preface','Problem_BulletList','Problem_Group','Problem_NumberedList','Problem_UnorderedList','Programlisting','REF-LIST','Series_Group','SL','TOC','Vignette_BulletList','Vignette_Group','Vignette_NumberedList','Vignette_UnorderedList',]\n",
    "\n",
    "\n",
    "# extract the xml of the document\n",
    "xml_string = doc.element.xml\n",
    "\n",
    "# parse the xml\n",
    "root = ET.fromstring(xml_string)\n",
    "# tag = []\n",
    "# # Iterate through the paragraphs in the document\n",
    "for sdt in root.findall('.//{http://schemas.openxmlformats.org/wordprocessingml/2006/main}sdtPr'):\n",
    "    tag = sdt.find('.//{http://schemas.openxmlformats.org/wordprocessingml/2006/main}tag').attrib['{http://schemas.openxmlformats.org/wordprocessingml/2006/main}val']\n",
    "    # unique_tags = [x for x in tag if x not in inlineTags]\n",
    "\n",
    "    print(tag)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import docx\n",
    "import csv\n",
    "from docx import *\n",
    "import os\n",
    "# document = Document('C:/Users/senthilps/Downloads/RL_docx (2)/RL_docx/RL_01_Amavilah_C001.docx')\n",
    "inlineTags = ['TBLCIT','title','gt','gd','DAY','MONTH','YEAR','Department','Country','CITY','INSTITUTION','STATE','AFFLABEL','email','URL','fnlink','AFFCIT','SURNAME','GIVENNAME','suffix','forename','prefix','degrees','AUTHOR','CORCIT','on-behalf-of','Bubble','REFCIT','FIGCIT','inlineequation','token','link','inline','chartlabel','chartcaption','CORAUTHOR','phone','fax','Rec','ACC','Rev','term','def','Speaker','line','SECCIT','figlabel','figcaption','figsource','figpara','figsource_break','alttext','SUPPCIT','seelink','FMT_Sub','Date','volume','issue','doi','edition','Editedby','imagelabel','imagecaption','Imprint','see','seealso','KW','KeywordTitle','ChartCIT','copyright','publicationdate','fpage','lpage','BOXCIT','CHAPCIT','PARTCIT','SUPPData','SchemesCIT','MapCIT','PlatesCIT','PhotoCIT','ImageCIT','Chapter','photolabel','photocaption','plateslabel','platescaption','page','type','REFID','journaltitle','pages','pubmed','crossref','chapter-title','publisher','labeltext','uri','season','misc','comment','supp','isbn','editor','booktitle','loc','collab','schemeslabel','schemescaption','seelabel','alt-text','tblfnlink','tbllabel','tblcaption','Abbreviation','Ack','AFFS','BACKMATTER','BL','BODYMATTER','Box_BulletList','Box_Group','Box_Group1','Box_NumberedList','Box_UnorderedList','CHAPTERBACKMATTER','CHAPTERFRONTMATTER','Contributors','Corresp-Group','Dialogue','Example_BulletList','Example_Group','Example_NumberedList','Example_UnorderedList','Extract','Extract_BulletList','Extract_Group','Extract_NumberedList','Extract_UnorderedList','Floats','Forward','FRONTMATTER','funding_group','glossary','glossary_text','Imprint_Group','Index','Index_Group','List_of_ILL','Math_BulletList','Math_Group','Math_NumberedList','Math_UnorderedList','NL','Part','Preface','Problem_BulletList','Problem_Group','Problem_NumberedList','Problem_UnorderedList','Programlisting','REF-LIST','Series_Group','SL','TOC','Vignette_BulletList','Vignette_Group','Vignette_NumberedList','Vignette_UnorderedList',]\n",
    "\n",
    "def pTagExtraction(docs):\n",
    "    dName, fName = os.path.split(docs)\n",
    "    c, ext = os.path.splitext(fName)\n",
    "    csvFileName = dName+\"/\"+c+\".csv\"\n",
    "    print(csvFileName)\n",
    "    aDoc = Document(docs)\n",
    "    stdTags = aDoc._element.xpath('.//ancestor::w:sdt//w:tag/@w:val')\n",
    "    docTags = [] \n",
    "    isfound = False\n",
    "    for tags in stdTags:\n",
    "        isfound = False\n",
    "        for itag in inlineTags:\n",
    "            if (tags.lower()==itag.lower()):\n",
    "                isfound=True\n",
    "                break\n",
    "        if(isfound == False):\n",
    "            docTags.append(tags)\n",
    "    \n",
    "    paraID = 1\n",
    "\n",
    "    with open(csvFileName, 'w', newline='') as pCSV:\n",
    "        fTags = csv.writer(pCSV)\n",
    "        fTags.writerow([\"paraID\", \"pTags\"]) \n",
    "        for prtag in docTags:\n",
    "            fTags.writerow([paraID, prtag])\n",
    "            paraID+=1\n",
    "   \n",
    "path = \"C:/Users/senthilps/Downloads/RL_docx (2)/RL_docx/\"  \n",
    "\n",
    "# collecting all the files in the folder\n",
    "# print(path)\n",
    "# pTagExtraction(path)\n",
    "dir_list = os.listdir(path)\n",
    "\n",
    "# print(dir_list[0])\n",
    "\n",
    "for p in dir_list:\n",
    "    aPath = path+\"/\"+p\n",
    "    # print(aPath)\n",
    "    pTagExtraction(aPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Half_Title', 'Book_Title', 'Sub_Title', 'Book_Author', 'Phrase', 'Phrase', 'Pub_Address', 'Phrase', 'Pub_Address', 'Holder', 'Legal_Notice', 'para', 'Legal_Notice', 'para', 'Legal_Notice', 'para', 'para', 'Legal_Notice', 'para', 'Dedication', 'para']\n"
     ]
    }
   ],
   "source": [
    "from docx import Document\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "# Open the Word document\n",
    "doc = Document('/Users/senthil/Desktop/Senthil/myTesting/python_scripts/content_controls/RL_00_ADCH_PRELIMS.docx')\n",
    "\n",
    "inlineTags = ['TBLCIT','title','gt','gd','DAY','MONTH','YEAR','Department','Country','CITY','INSTITUTION','STATE','AFFLABEL','email','URL','fnlink','AFFCIT','SURNAME','GIVENNAME','suffix','forename','prefix','degrees','AUTHOR','CORCIT','on-behalf-of','Bubble','REFCIT','FIGCIT','inlineequation','token','link','inline','chartlabel','chartcaption','CORAUTHOR','phone','fax','Rec','ACC','Rev','term','def','Speaker','line','SECCIT','figlabel','figcaption','figsource','figpara','figsource_break','alttext','SUPPCIT','seelink','FMT_Sub','Date','volume','issue','doi','edition','Editedby','imagelabel','imagecaption','Imprint','see','seealso','KW','KeywordTitle','ChartCIT','copyright','publicationdate','fpage','lpage','BOXCIT','CHAPCIT','PARTCIT','SUPPData','SchemesCIT','MapCIT','PlatesCIT','PhotoCIT','ImageCIT','Chapter','photolabel','photocaption','plateslabel','platescaption','page','type','REFID','journaltitle','pages','pubmed','crossref','chapter-title','publisher','labeltext','uri','season','misc','comment','supp','isbn','editor','booktitle','loc','collab','schemeslabel','schemescaption','seelabel','alt-text','tblfnlink','tbllabel','tblcaption','Abbreviation','Ack','AFFS','BACKMATTER','BL','BODYMATTER','Box_BulletList','Box_Group','Box_Group1','Box_NumberedList','Box_UnorderedList','CHAPTERBACKMATTER','CHAPTERFRONTMATTER','Contributors','Corresp-Group','Dialogue','Example_BulletList','Example_Group','Example_NumberedList','Example_UnorderedList','Extract','Extract_BulletList','Extract_Group','Extract_NumberedList','Extract_UnorderedList','Floats','Forward','FRONTMATTER','funding_group','glossary','glossary_text','Imprint_Group','Index','Index_Group','List_of_ILL','Math_BulletList','Math_Group','Math_NumberedList','Math_UnorderedList','NL','Part','Preface','Problem_BulletList','Problem_Group','Problem_NumberedList','Problem_UnorderedList','Programlisting','REF-LIST','Series_Group','SL','TOC','Vignette_BulletList','Vignette_Group','Vignette_NumberedList','Vignette_UnorderedList',]\n",
    "\n",
    "final_tags = []\n",
    "# extract the xml of the document\n",
    "xml_string = doc.element.xml\n",
    "\n",
    "# parse the xml\n",
    "root = ET.fromstring(xml_string)\n",
    "\n",
    "# Iterate through the paragraphs in the document\n",
    "for sdt in root.findall('.//{http://schemas.openxmlformats.org/wordprocessingml/2006/main}sdtPr'):\n",
    "    tag = sdt.find('.//{http://schemas.openxmlformats.org/wordprocessingml/2006/main}tag').attrib['{http://schemas.openxmlformats.org/wordprocessingml/2006/main}val']\n",
    "\n",
    "    if tag not in inlineTags:\n",
    "        final_tags.append(tag)\n",
    "\n",
    "# print(final_tags)\n",
    "\n",
    "def join_l(l, sep):\n",
    "    li = iter(l)\n",
    "    string = str(next(li))\n",
    "    for i in li:\n",
    "        string += str(sep) + str(i)\n",
    "    return string\n",
    "\n",
    "replace_text = join_l(final_tags, \"|\")\n",
    "\n",
    "req_text = replace_text.replace(\"Legal_Notice|para|para\",\"Legal_Notice\")\n",
    "req_text1 = req_text.replace(\"Legal_Notice|para\",\"Legal_Notice\")\n",
    "\n",
    "req_text2 = req_text1.split(\"|\")\n",
    "\n",
    "print(req_text2)\n",
    "\n",
    "# updated_tags = [x.replace(\"Legal_Notice\\npara\", \"Legal_Notice\") for x in final_tags]\n",
    "\n",
    "# for ftags in updated_tags:\n",
    "#     # if ftags==\"Legal_Notice\\sPara\":\n",
    "#     print(ftags)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Half_Title', 'Book_Title', 'Sub_Title', 'Book_Author', 'Phrase', 'Phrase', 'Pub_Address', 'Phrase', 'Pub_Address', 'Holder', 'Legal_Notice', 'Legal_Notice', 'Legal_Notice', 'Legal_Notice', 'Dedication', 'para']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "final_tags = ['Half_Title', 'Book_Title', 'Sub_Title', 'Book_Author', 'Phrase', 'Phrase', 'Pub_Address', 'Phrase', 'Pub_Address', 'Holder', 'Legal_Notice', 'para', 'Legal_Notice', 'para', 'Legal_Notice', 'para', 'para', 'Legal_Notice', 'para', 'Dedication', 'para']\n",
    "\n",
    "# updated_tags = []\n",
    "# for tag in final_tags:\n",
    "#     if tag == \"Legal_Notice\" and updated_tags[-1] == \"para\":\n",
    "#         updated_tags.pop()\n",
    "#     else:\n",
    "#         updated_tags.append(tag)\n",
    "\n",
    "# print(updated_tags)\n",
    "\n",
    "def join_l(l, sep):\n",
    "    li = iter(l)\n",
    "    string = str(next(li))\n",
    "    for i in li:\n",
    "        string += str(sep) + str(i)\n",
    "    return string\n",
    "\n",
    "replace_text = join_l(final_tags, \"|\")\n",
    "\n",
    "req_text = replace_text.replace(\"Legal_Notice|para|para\",\"Legal_Notice\")\n",
    "req_text1 = req_text.replace(\"Legal_Notice|para\",\"Legal_Notice\")\n",
    "\n",
    "req_text2 = req_text1.split(\"|\")\n",
    "\n",
    "print(req_text2)\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word count details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word count of /Users/senthil/Desktop/Senthil/myTesting/python_scripts/content_controls/TNFUK_03_ORJU-TS_C003.docx including footnotes and endnotes is: 7261\n"
     ]
    }
   ],
   "source": [
    "from lxml import etree\n",
    "import docx\n",
    "\n",
    "def word_count(file_path):\n",
    "    doc = docx.Document(file_path)\n",
    "    full_text = []\n",
    "    for para in doc.paragraphs:\n",
    "        full_text.append(para.text)\n",
    "\n",
    "    xml_content = doc._element.xml\n",
    "    tree = etree.fromstring(xml_content)\n",
    "    footnotes = tree.xpath(\".//w:footnoteReference/following-sibling::w:footnote[@w:id]\",\n",
    "                           namespaces={'w': 'http://schemas.openxmlformats.org/wordprocessingml/2006/main'})\n",
    "    endnotes = tree.xpath(\".//w:endnoteReference/following-sibling::w:endnote[@w:id]\",\n",
    "                          namespaces={'w': 'http://schemas.openxmlformats.org/wordprocessingml/2006/main'})\n",
    "    for note in footnotes + endnotes:\n",
    "        text_elements = note.xpath(\".//w:t\",\n",
    "                                   namespaces={'w': 'http://schemas.openxmlformats.org/wordprocessingml/2006/main'})\n",
    "        note_text = ''.join(text.text for text in text_elements)\n",
    "        full_text.append(note_text)\n",
    "    return len(str('\\n'.join(full_text)).split())\n",
    "\n",
    "file_path = \"/Users/senthil/Desktop/Senthil/myTesting/python_scripts/content_controls/TNFUK_03_ORJU-TS_C003.docx\"\n",
    "word_count = word_count(file_path)\n",
    "print(\"Word count of {} including footnotes and endnotes is: {}\".format(file_path, word_count))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def extract_docx_to_list(file_path):\n",
    "#     # Open the Word document\n",
    "#     doc = docx.Document(file_path)\n",
    "\n",
    "#     # Initialize an empty list to store extracted text\n",
    "#     docx_para_list = []\n",
    "\n",
    "#     # Iterate through each element in the document\n",
    "#     for element in doc.element.xpath('.//*'):\n",
    "#         # Check if the element is a paragraph\n",
    "#         if element.tag.endswith('}p'):\n",
    "#             # Skip paragraphs that are inside table cells\n",
    "#             if element.getparent().tag.endswith('}tc'):\n",
    "#                 continue\n",
    "#             # Get all text elements in the paragraph\n",
    "#             text_elements = element.xpath('.//w:t')\n",
    "#             if text_elements:\n",
    "#                 # Concatenate the text from all text elements\n",
    "#                 text = ''.join([text_element.text for text_element in text_elements])\n",
    "#                 docx_para_list.append(text)\n",
    "\n",
    "#         # Check if the element is a table\n",
    "#         elif element.tag.endswith('}tbl'):\n",
    "#             # Iterate through each row in the table\n",
    "#             for row in element.xpath('.//w:tr'):\n",
    "#                 # Iterate through each cell in the row\n",
    "#                 for cell in row.xpath('.//w:tc'):\n",
    "#                     cell_text = []\n",
    "#                     # Get all paragraphs in the cell\n",
    "#                     for paragraph in cell.xpath('.//w:p'):\n",
    "#                         runs = paragraph.xpath('.//w:r')\n",
    "#                         cell_text_by_paragraph = \"\"\n",
    "#                         # Concatenate the text from all runs in each paragraph\n",
    "#                         for run in runs:\n",
    "#                             run_text = run.xpath('.//w:t')\n",
    "#                             if run_text:\n",
    "#                                 cell_text_by_paragraph += run_text[0].text\n",
    "#                         cell_text.append(cell_text_by_paragraph)\n",
    "\n",
    "#                     # Check if the cell contains a dropdown list\n",
    "#                     result_val = cell.xpath('.//w:r/w:fldChar/w:ffData/w:ddList/w:result/@w:val')\n",
    "#                     if result_val:\n",
    "#                         selected_value = cell.xpath('.//w:ffData/w:ddList/w:listEntry/@w:val')\n",
    "#                         # selected_value = result_val[0].getparent().xpath('.//ancestor::w:ddList/w:listEntry/@w:val', namespaces=ns_map)\n",
    "#                         if selected_value:\n",
    "#                             # Iterate through each paragraph in the cell and add the selected value for each dropdown to the list\n",
    "#                             for i, cell_text_by_paragraph in enumerate(cell_text):\n",
    "#                                 if i < len(result_val) and i < len(selected_value):\n",
    "#                                     docx_para_list.append(f\"{cell_text_by_paragraph} {selected_value[int(result_val[i])]}\")\n",
    "#                                 else:\n",
    "#                                     docx_para_list.append(cell_text_by_paragraph)\n",
    "#                         else:\n",
    "#                             # Iterate through each paragraph in the cell and add its text to the list\n",
    "#                             for cell_text_by_paragraph in cell_text:\n",
    "#                                 docx_para_list.append(cell_text_by_paragraph)\n",
    "#                     else:\n",
    "#                         # Iterate through each paragraph in the cell and add its text to the list\n",
    "#                         for cell_text_by_paragraph in cell_text:\n",
    "#                             docx_para_list.append(cell_text_by_paragraph)\n",
    "\n",
    "#     return docx_para_list\n",
    "\n",
    "# text = extract_docx_to_list(file_path)\n",
    "\n",
    "# text = pdf_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Replace 'your_file.xlsx' with the actual file path\n",
    "file_path = '/Users/senthil/Desktop/Senthil/my_testing/Project_Creation/testing_briefs/CEUP Handover Template_Mikecz.xlsx'\n",
    "\n",
    "# Read the Excel file and extract the first sheet\n",
    "df = pd.read_excel(file_path, sheet_name=0)\n",
    "\n",
    "# Drop rows with NaN values\n",
    "df_cleaned = df.dropna()\n",
    "\n",
    "\n",
    "# Display the extracted data\n",
    "df_cleaned\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PDF to text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Purchase Order', 'Academic - PROJECT MANAGEMENT', 'Bloomsbury', 'Publishing', 'Bill To:', 'Bloomsbury Publishing (UK)', '50 Bedford Square, London, WC1B', '3DP', 'Telephone: (0)20 7631 5600', 'Fax: (0)20 7631 5800', 'Email:', 'bloomsburyaccounts@bloomsbury.com', 'To:', 'Deanta - UK-owned', '51 Clontarf Road', 'Dublin 3', 'Contact', 'Sophie Beardsworth, Email: sophie.beardsworth@bloomsbury.com', 'PO Number', '00187210', 'Date', '05/10/2023', 'Title', 'Reformed Humanism', 'Author', 'David Fergusson', 'Delivery Date', '11/01/2024', 'Edition', 'Edition', 'ISBN', 'ISBN', 'Price', 'Price', 'HS Code', 'HS Code', '    1 - Hardback ', '- 001.01 - Bloomsbury PLC, Academic and Professional Division', '9780567712745', '£85.00', 'BK', 'Common Specification', 'Common Specification', '  ', 'Product Type  ', 'Book', '  ', 'Extent  ', '256', '  ', 'Format  ', '234 x 156mm - ', 'trimmed.', ' ', '234mm (9', '/', '(h)', ' x 156mm (6', '/', '(w)', '  ', 'Preparation & Text  ', 'Text Print:', ' 1x1. ', 'Print From:', ' PDF.', '  ', 'Page Complexity  ', 'Medium', '  ', 'Text Design  ', ' Page Template - ', 'Text Template', ': Monograph D.', '  ', 'Cover and Jackets  ', ' PLC Only.', '  ', 'Endpapers  ', ' Endpapers - ', 'End Paper', ': Plain.', 'Notes', 'Notes', 'Please see the PM Brief for full details and instructions on this project.', 'Please supply project-management services for this title, according to the terms of the Bloomsbury SLA.', 'Cost Breakdown', 'Cost Breakdown', 'Notes', 'Notes', 'Total', 'Total', 'Common costs', '  Project Management (256 pages) @ £4.6000 Per Page, runon £4.6000', '£1,177.60 GBP', 'Total', 'Total', '£1,177.60 GBP', 'Signed on behalf of T&T Clark - Bloomsbury Publishing (UK)', 'Signed on behalf of T&T Clark - Bloomsbury Publishing (UK)', 'Sophie Beardsworth', 'Payment of invoice is contingent upon supplier meeting the full terms of Bloomsbury SLA.', '7', '32', '\") ', '9', '64', '\") ']\n"
     ]
    }
   ],
   "source": [
    "import PyPDF2\n",
    "\n",
    "def extract_text(filepath, text=[]):\n",
    "    # Open the PDF file in read-binary mode\n",
    "    pdf_reader = PyPDF2.PdfReader(filepath)\n",
    "\n",
    "    # Get the number of pages in the PDF file\n",
    "    \n",
    "    num_pages = len(pdf_reader.pages)\n",
    "\n",
    "    # Loop over each page and extract the text\n",
    "    for page_num in range(num_pages):\n",
    "        page = pdf_reader.pages[page_num]\n",
    "        text += page.extract_text().split(\"\\n\")\n",
    "\n",
    "\n",
    "    return text\n",
    "\n",
    "\n",
    "pdf_text = extract_text(\"/Users/senthil/Desktop/Senthil/my_testing/Project_Creation/testing_briefs/PO20231005_Reformed Humanism_Deanta.pdf\")\n",
    "\n",
    "print(pdf_text)\n",
    "# for txt in pdf_text:\n",
    "#     print(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"/Users/senthil/Downloads/PM Brief Form.docx\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project Management Brief – Academic Production\tBasic Details\tTitle: The Thought of Pope Benedict XVI\tSubtitle: An Introduction to the Theology of Joseph Ratzinger\tSeries:\tBloomsbury Production contact: Sophie Beardsworth\tPublication: June 2024\tRequested finals date: 30 January 2024\tContact Details\tName:\tRole:\tEmail:\tRev Dr Aidan Nichols\tAuthor\tfraidannichols@outlook.com\tCopy-edit queries sent to: Authors/Editors listed above\tProofs to go to: Authors/Editors listed above and Bloomsbury Production contact\tAny known unavailability: N/A\tConfidential author/editor notes: The author has written many books - but sometimes runs into issues with technology: a little patience may be required through the process.\tText Specifications\tTPS: 234 x 156mm\tOther: N/A\tText colour(s):\tFurther details (colours, etc.): N/A\tText design template: Monograph D\tIf ‘Custom’, or any changes to text design specs:\tAny further text design details/additional notes for typesetter: Please watch out for formatting issues deriving from PDF to Word conversions\tNotes placement: Footnotes\tFurther details: Footnotes will need to be re-linked: please ensure they are set consistently. See below for more detailed information.\tBibliography/References placement: End of book\tFurther details: The content should be fine, but the formatting is probably all over the place.\tFurther Reading placement: N/A\tFurther details: N/A\tIndex: Yes ☒ No ☐ Compiled by: Project Manager\tFurther details: List of terms provided (re-using Index from second edition) but page numbers to be filled in. Might require some reformatting as the conversion has mis-aligned the Index.\tAny missing material: ☐ Specify:\tDate due: N/A\tCopy-Edit / Proofing\tProject complexity: Complex\tIf ‘Complex’: While I've set this as complex, the MS itself isn't complex, but just quite fiddly.\tIt's a third edition, which has been converted from PDF to Word so the author can add what is required.\tAs such, the formatting is a little all over the place and it will require careful work to rectify. See below for specific details to look out for.\tLevel of copy-editing required: Medium\tElaborate: this sits on the border of Invasive/Medium: the text itself will not require much work and can be a medium, but the referencing will require a lot of re-formatting and work.\t- Notes will need to be re-linked (Chapter I, XVI, XVII are ok but the numbering is out of order)\t- Some chapters, which have been edited by the author (e.g. Chapters XI, XIV, XV, Conclusion) have both linked and unlinked notes, which means the numbering jumps. e.g. Chapter XV goes from 88, to 197, then from 217 back to 89. These will require careful re-numbering and sorting out.\t- Hyphenation of words that were split across lines in the previous PDF will need to be uhyphenated (e.g. they appear in the middle of a line as such: 'this undeser- ved reference')\t- Margins / layout of the MS is a bit changeable\t- Text sizing, spacing, and font is changeable\tI've run through the first chapter and prelims, and re-linked the notes to those and seen the correspondant formatting errors - let me know if you have any queries.\tFor clarity, the new additions to the third edition are: New Preface to the Third Edition, New Chapter II 'The Life: Cisalpine', extensions to Chapter VIII 'Reflections on the Creed', extensions to Chapter XIV 'The Prefect', New Chapter XVI 'Benedict's Jesus', New Chapter XVII 'The Pope of the Virtues' and New Chapter XVIII 'Theologian of the Polis'. Also there are some additions to the Bibliography.\tSpecific notes for copy-editor:\t- Elide page ranges where possible through the text - the notes in particular need a lot of number elision. Look out for where years can be elided as well.\t- Ensure en dashes between page and year ranges, not hyphens\t- Ensure spaces between initials for names in Bibliography - most seems to be ok, but with the inconsistent formatting, errors may be present\t- Ensure small caps for BC / AD or BCE / CE\t- Biblical references should use hyphens between verses and en rules between chapters.\tHouse style to apply: Bloomsbury Academic UK\tIf ‘Other’/further details to note: While most of the MS is UK, the BIbliocal references appear to be US. Please stick with whatever has been done in the previous editions.\tAdditional styles: T&T Clark\tReferencing style: As per selected house style\tIf ‘Other’/further details to note: Bibliography is short title.\tPlease elide number ranges as far as possible. Alignment issues to watch out for.\tNumbered list in references: will need retaining. Consult new first edition for reference if anything looks very out of order.\tSupplementary Information\t\tOnline resources: ☐\tIf ticked, provide details: N/A\tArtwork\tCheck that all halftone images will be at least 300 dpi and line diagrams at least 600 dpi when at their final size on the page. Do not resample any images. Check and adjust colour levels and contrast to ensure that all images will reproduce clearly and legibly in print and in the ebooks. Alert Bloomsbury Production if any images are low resolution or of poor quality. Any images supplied in colour should be retained as colour images in the ebook editions and XML unless otherwise indicated.\tArtwork: ☐\tArtwork log supplied:\tLine drawings:\tMaps:\tTables:\tHalftones:\tArtwork to be printed mono: ☐\tArtwork to be printed colour: ☐\tCallouts in MS: ☐\tFurther details: N/A\tCaptions provided: ☐\tNotes on captions: N/A\tList of illustrations provided: ☐\tNotes/placement: N/A\tAny art-working required:\tAdditional notes on images:\tPlate sections\tDetails:\tPlate section(s)/tip-ins: ☐\tXML and Metadata\tTitle needs to follow XML ID Persistence workflow: ☐\t(Production Editor: check if title is Major Reference)\tXML schema:\tAdditional XML notes: N/A\tAbstracts and keywords provided: ☐\tWhere provided, please copy-edit Abstracts and Keywords to house style selected above, and compile into XML deliverable. DO NOT TYPESET.\tISBNs:\tHardback:\t9781350431133\tPaperback:\t9781350431126\tePub:\t9781350431140\tePDF:\t9781350431157\tXML:\t9781350431164\tNote to Project Manager: cross-check ISBNs in manuscript/source material against those above.\tEdition description:\tThis important and illuminating book focuses on Ratzinger's status as one of the preeminent Catholic theologians of the 20th century. Aidan Nichols provides a full-scale investigation of his theology as it develops from the 1950s onward. The book presents a chronological account of the development of Ratzinger's writing which reflects a wide range of historical and theoretical interests such as: Augustine's ecclesiology, early Franciscanism and the idea of salvation history, Christian brotherhood, the unfolding of the Second Vatican Council the Apostle's Creed, explorations of the concept of the Church, preaching, liturgy and Church music, eschatology, the foundations of dogmatic and moral theology, and the problem of pluralism.This updated and revised edition remains a comprehensive introduction to a major theologian in his own right, quite apart from his significance in the politics of the Church. For those attempting to chart the future of the Catholic faith as it struggles with the role of religion in war, women's reproductive rights, inter-religious dialogue, homosexuality, the roles of bishops and theologians, and international human rights issues, Nichol's work is indispensable as both a compass and an oracle.\tAuthor/editor name(s):\tID(s):\tBiography/ies:\tAidan Nichols\t32479\tAidan Nichols OP is Lector and Fellow of Blackfriars Hall at the University of Oxford, UK.\n",
      "Binding details not found\n",
      "╒═══════════════════╤═════════════════════════════════════════════════════╕\n",
      "│ Key               │ Metadata                                            │\n",
      "╞═══════════════════╪═════════════════════════════════════════════════════╡\n",
      "│ book_title        │ The Thought of Pope Benedict XVI                    │\n",
      "├───────────────────┼─────────────────────────────────────────────────────┤\n",
      "│ subtitle          │ An Introduction to the Theology of Joseph Ratzinger │\n",
      "├───────────────────┼─────────────────────────────────────────────────────┤\n",
      "│ series            │ Bloomsbury Production contact: Sophie Beardsworth   │\n",
      "├───────────────────┼─────────────────────────────────────────────────────┤\n",
      "│ author            │ Rev  Aidan Nichols                                  │\n",
      "├───────────────────┼─────────────────────────────────────────────────────┤\n",
      "│ author_mailid     │ fraidannichols@outlook.com                          │\n",
      "├───────────────────┼─────────────────────────────────────────────────────┤\n",
      "│ isbn              │ 9781350431133                                       │\n",
      "├───────────────────┼─────────────────────────────────────────────────────┤\n",
      "│ hardback_isbn     │ 9781350431133                                       │\n",
      "├───────────────────┼─────────────────────────────────────────────────────┤\n",
      "│ paperback_isbn    │ 9781350431126                                       │\n",
      "├───────────────────┼─────────────────────────────────────────────────────┤\n",
      "│ epub_isbn         │ 9781350431140                                       │\n",
      "├───────────────────┼─────────────────────────────────────────────────────┤\n",
      "│ epub2_isbn        │ 9781350431164                                       │\n",
      "├───────────────────┼─────────────────────────────────────────────────────┤\n",
      "│ ebook_master      │ 9781350431157                                       │\n",
      "├───────────────────┼─────────────────────────────────────────────────────┤\n",
      "│ project_endDate   │ 30 January 2024                                     │\n",
      "├───────────────────┼─────────────────────────────────────────────────────┤\n",
      "│ production_editor │ Sophie Beardsworth                                  │\n",
      "├───────────────────┼─────────────────────────────────────────────────────┤\n",
      "│ text_design       │ Monograph D                                         │\n",
      "├───────────────────┼─────────────────────────────────────────────────────┤\n",
      "│ trim_size         │ 234 x 156                                           │\n",
      "├───────────────────┼─────────────────────────────────────────────────────┤\n",
      "│ Indexer           │ Project Manager                                     │\n",
      "╘═══════════════════╧═════════════════════════════════════════════════════╛\n"
     ]
    }
   ],
   "source": [
    "import docx, re\n",
    "import tabulate as tab\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "\n",
    "ns_map={\"w\": \"http://schemas.openxmlformats.org/wordprocessingml/2006/main\"}\n",
    "\n",
    "def extract_docx_to_list(file_path):\n",
    "    \"\"\"\n",
    "    Extract text from a Word (docx) document and store it in a list.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): The file path to the Word document (docx).\n",
    "\n",
    "    Returns:\n",
    "        list: A list containing extracted text from the document.\n",
    "\n",
    "    Note:\n",
    "        This function assumes the availability of the following:\n",
    "        - docx.Document from the python-docx library.\n",
    "        - ElementTree from the xml.etree.ElementTree library.\n",
    "        - ns_map: Namespace mapping required for XPath queries.\n",
    "    \"\"\"\n",
    "    # Open the Word document\n",
    "    doc = docx.Document(file_path)\n",
    "\n",
    "    # Initialize an empty list to store extracted text\n",
    "    docx_para_list = []\n",
    "    words_to_remove = ['FORMDROPDOWN', 'FORMTEXT']\n",
    "\n",
    "    for para in doc.element.xpath('//w:p'):\n",
    "        # Extract text nodes from the paragraph\n",
    "        text_nodes = para.xpath('.//text()')\n",
    "        if text_nodes:\n",
    "            para_text = ''.join(text_nodes)\n",
    "            # Remove specified words from the text\n",
    "            para_split = [word for word in para_text.split() if word not in words_to_remove]\n",
    "            para_text = ' '.join(para_split)\n",
    "            result_val = para.xpath('.//w:r/w:fldChar/w:ffData/w:ddList/w:result/@w:val')\n",
    "            if result_val:\n",
    "                for value in result_val:\n",
    "                    # Extract selected value from dropdown field\n",
    "                    selected_value = value.getparent().xpath('.//ancestor::w:ddList/w:listEntry/@w:val', namespaces=ns_map)\n",
    "                    para_text += \" \" + selected_value[int(value)]\n",
    "            docx_para_list.append(para_text)\n",
    "\n",
    "    return docx_para_list\n",
    "\n",
    "text = extract_docx_to_list(file_path)\n",
    "\n",
    "\n",
    "def find_text_with_regexes(regex_dict, text):\n",
    "    # Create an empty dictionary to hold the results\n",
    "    results = {}\n",
    "    my_text = '\\t'.join(text)\n",
    "    print(my_text)\n",
    "    # Loop through each label and regex in the dictionary\n",
    "    for label, regex in regex_dict.items():\n",
    "        # Use regex to search for the pattern in the text\n",
    "        # print(f\"Searching for label '{label}' with regex '{regex}'\")\n",
    "        match = re.search(regex, my_text)\n",
    "\n",
    "        # If a match is found, add it to the results dictionary with the current label as the key\n",
    "        if match:\n",
    "            # print(f\"Found match '{match.group(2)}'\")\n",
    "            results[label] = match.group(2).strip()\n",
    "        # else:\n",
    "        #     print(f\"{label} not found\")\n",
    "\n",
    "    # Return the results dictionary\n",
    "    return results\n",
    "\n",
    "\n",
    "regex_dict = {\"book_title\":\"(?i)(book\\s+title|title(?<!Subtitle))(?::|,|-|–)?\\s?(.+?(?=\\t))\",\n",
    "\"subtitle\":\"(?i)(book\\ssub\\s?title|sub\\s?title)(?::|,|-|–)?\\s?(.+?(?=\\t))\",\n",
    "\"series\":\"(?i)(Series)(?::|,|-|–)?\\s?(.+?(?=\\t))\",\n",
    "\"author\":\"(Name:\\s?Role:\\s?Email:|Author\\/Eds|Author(?:s?)(?:\\(s\\))?|contact\\sauthor(?:s?)(?:\\(s\\))|(?<!Anthem\\s)Editor(?:s)?(?:\\(s\\))?|Contributor(?:s?)(?:\\(s\\)))(?::|,|-|–)?\\s?(.+?(?=\\t))\",\n",
    "\"author_mailid\":\"(?i)((?:Email(?::|,|-|–)?(?:\\t).+?\\t?(?:Editor|Author)\\t?)|\\(email|Author Contact.+?)[:]?\\s?([a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\\.[a-zA-Z0-9-.]+)\",\n",
    "\"isbn\":\"(?i)(ISBN)\\s?(?<!E-ISBN)(?:[:,-–])?(:?\\t?.+?)(?<=\\t)\",\n",
    "\"hardback_isbn\":\"(?i)(ISBN\\s\\(hardback\\)|ISBN\\s\\(hard|cloth\\)|hardback)\\s?(?::|,|-|–)?\\s?(.+?(?=\\t))\",\n",
    "\"paperback_isbn\":\"(?i)(ISBN\\s\\(paperback\\)|ISBN\\s\\(paper\\)|paperback|NIPPOD)\\s?(?::|,|-|–)?\\s?(.+?(?=\\t))\",\n",
    "\"epub_isbn\":\"(?i)(ePub\\sebook|ePub|ISBN\\s\\(elec\\.\\)):\\s?(?::|,|-|–)?\\s?(.+?(?=\\t))\",\n",
    "\"epub2_isbn\":\"(?i)(XML)\\s?(?::|,|-|–)\\s?(.+?(?=\\t))\",\n",
    "\"ebook_master\":\"(?i)((?<!for\\s)ePDF|Web\\sPDF|(?<!ePub\\s)ebook|(?<!print-ready\\s)\\bPDF\\b|E-ISBN)\\s?(?::|,|-|–)\\s?(.+?(?=\\t))\",\n",
    "\"isbn_opt\":\"(?i)(\\s)?(.+?(?=\\t))\\((ISBN(?:\\s?))\\)\",\n",
    "\"hardback_isbn_opt\":\"(?i)(ISBNs:\\s+)(.+?)\\((Hardback)\\)\",\n",
    "\"paperback_isbn_opt\":\"(?i)(\\s)?(.+?(?=\\t))\\((paperback)\\)\",\n",
    "\"epub_isbn_opt\":\"(?i)(\\(hardback\\)\\s+)(.+?)(\\s+\\(ePub\\))\",\n",
    "\"ebook_master_opt\":\"(?i)(\\(ePub\\)\\s+)(.+?)\\((Web\\sPDF\\/XHTML)\\)\",\n",
    "\"po_number\":\"(?i)(PO\\sNumber|MUP\\skeycode|Purchase\\sOrder(?:\\sNumber)?|P\\.O\\.\\s\\#)\\s?(?::|,|-|–)?\\s?([\\w\\d-]+?(?=\\t)(he\\/him)?)\",\n",
    "\"page_count\":\"(?i)(Estimated\\sprint\\sextent|Estimated\\spage\\sextent|Est\\.\\sfinal\\spp\\scount|Extent)\\s?(?::|,|-|–)?\\s?(.+?(?=\\t))\",\n",
    "\"project_startDate\":\"(?i)(Handover\\sdate|start\\sdate|date(?<!Requested\\sfinals\\sdate)(?!\\sdue|s\\sare styled|\\sreferences used in|\\sreferences).\\))\\s?(?::|,|-|–)?\\s?(.+?(?=\\t))\",\n",
    "\"project_endDate\":\"(?i)(Target\\ssend-to-print\\sdate\\sFinal\\sdue|Requested\\sfinals\\sdate|Target\\ssend-to-print\\sdate|Schedule:\\sReturn\\smanuscript\\sby|Final\\sPDF\\s\\+\\sPOD\\sfiles|Printer\\sDate|Final\\sPDF\\sdue|End date)\\s?(?::|,|-|–)?\\s?(?:late\\s|spring|Publication date)?(.+?(?=\\t))\",\n",
    "\"production_editor\":\"(?i)(Bloomsbury\\sProduction\\scontact|Anthem\\sEditor|Production\\sEditor|\\t?(?<!Print\\s)From|Bloomsbury Production Editor|\\bPE\\b|Contact)\\s?(?::|,|-|–)?(.+?(?=\\t|,\\sEmail))\",\n",
    "\"project_manager\":\"(?i)(To)\\s?(?:[:,-–])?(?:[:,-–]?\\s+)?(.+?(?=\\t))(,\\s?Deanta Global)\",\n",
    "\"text_design\":\"(?i)(Text Template|Text\\sdesign\\stemplate|Text\\sdesign|^template|Design\\stemplate|Layout\\sstyle.+?X|\\\\bDesign\\\\b)\\s?(?::|,|-|–)?\\s?(?![\\s:,-–]*Page Template\\s-\\s)(.+?(?=\\t))\",\n",
    "\"trim_size\":\"(?i)(TPS|Page\\strim|Format|Trim\\ssize|Trim)(?:[:,-–]?)\\s?(?:\\s{1,})?(\\d{1,3}\\s?(?:\\.?\\d{1,3}?)?\\s?x\\s?\\d{1,3}\\.?(?:\\.?\\d{1,3}?)?\\s?)\\s?(?:mm|in)?(?:.+?)(?=\\t)\",\n",
    "\"Indexer\":\"(?i)(Index[:]\\sYes\\s☒\\sNo\\s☐\\s+Compiled\\sby[:]\\s+)(.+?(?=\\t))\",\n",
    "\"productioneditor_mailid\":\"(?i)(, Email(?::|,|-|–)?)(.+?(?=\\t))\",\n",
    "\"binding\":\"(?i)(Price\\s+\\d+\\s[-]\\s)(.+?(?=\\t))\",\n",
    "\"binding_opt\":\"(?i)(ISBN(?:\\s)?)(?:\\()(cloth)|paper(?:\\))[:, ](978.+?(?=\\t))\",\n",
    "\"published_date\":\"(?i)(Target\\spublication\\sdate)\\s?(?::|,|-|–)?\\s??(.+?(?=\\t))\",\n",
    "\"Imprint\":\"(Imprint)\\s?(?::|,|-|–)?\\s??(.+?(?=\\t))\"\n",
    "}\n",
    "\n",
    "\n",
    "results = find_text_with_regexes(regex_dict, text)\n",
    "\n",
    "# cleanup the extracted texts\n",
    "\n",
    "def metadata_cleanup(results):    \n",
    "\n",
    "    # removing \":\" from isbn\n",
    "    pattern = r\"\\.|\\d+\\.\\d+ - First Printing|£\\d+\\.\\d+ GBP|[-\\s:]|\\(cloth\\)|\\(paper\\)|\\(elec\\.\\)|\\bN(?:\\/)?A\\b|\\(delayed\\)|\\(?\\t?[hH]ardback\\)?|\\(?[pP]aperback\\)?|\\(?NIPPOD\\)?|ISBN|Paperback|£\\d+\\.\\d+GBP|\\)|None|ePub,andXMLs|SBN(?:\\:?)|\\d+\\.\\d+\\s-\\sBloomsbury\\sPublishing\\sPLC\"\n",
    "\n",
    "    # List of keys for which the ISBN values need to be cleaned\n",
    "    isbn_keys_to_clean = [\"isbn\", \"hardback_isbn\", \"paperback_isbn\", \"epub_isbn\", \"epub2_isbn\", \"ebook_master\", \"isbn_opt\", \"hardback_isbn_opt\", \"paperback_isbn_opt\", \"epub_isbn_opt\", \"ebook_master_opt\"]\n",
    "    # Clean ISBN values for each key in 'keys_to_clean'\n",
    "    for key in isbn_keys_to_clean:\n",
    "        if key in results and results[key] is not None:\n",
    "            # print(f\"harback ISBN: {results[key]}\")\n",
    "            results[key] = re.sub(pattern, \"\", results[key])\n",
    "\n",
    "    # replacing the \"isbn\" with \"hardback_isbn\"\n",
    "    try:\n",
    "        if not results[\"isbn\"]:\n",
    "            _default_hardback_isbn = results.get(\"hardback_isbn\", \"\")\n",
    "            results[\"isbn\"]= _default_hardback_isbn\n",
    "            if not results[\"isbn\"]:\n",
    "                _default_paperback_isbn = results.get(\"paperback_isbn\", \"\")\n",
    "                results[\"isbn\"]= _default_paperback_isbn\n",
    "\n",
    "        isbn_mapping = {\n",
    "        \"hardback_isbn\": \"hardback_isbn_opt\",\n",
    "        \"paperback_isbn\": \"paperback_isbn_opt\",\n",
    "        \"epub_isbn\": \"epub_isbn_opt\",\n",
    "        \"ebook_master\": \"ebook_master_opt\"\n",
    "        }\n",
    "\n",
    "        for isbn_type, optional_key in isbn_mapping.items():\n",
    "            if not results[isbn_type]:\n",
    "                results[isbn_type] = results.get(optional_key, \"\")\n",
    "    \n",
    "    except:\n",
    "        print(\"ISBN is not found\")\n",
    "\n",
    "\n",
    "    # replacing the binding details as \"Hardback\" or \"Paperback\"\n",
    "    binding_mapping = {\n",
    "            \"cloth\": \"Hardback\",\n",
    "            \"paper\": \"Paperback\"\n",
    "        }\n",
    "    try:\n",
    "        binding_opt = results.get(\"binding_opt\")\n",
    "        print(\"binding_opt: \"+results[\"binding_opt\"])\n",
    "        if not results.get(\"binding\", \"\") and binding_opt in binding_mapping:\n",
    "            results[\"binding\"] = binding_mapping[binding_opt]\n",
    "            # print(\"binding: \"+results[\"binding\"])\n",
    "    except:\n",
    "        print(\"Binding details not found\")\n",
    "\n",
    "\n",
    "    # removing prefix from \"author\"\n",
    "    authors_pattern = \"(?i)\\(.+?\\)|\\\\b(?:Dr(\\.)?|^Edited by |, Rowman \\& Littlefield|\\(R\\&L template\\)|\\bN(?:\\/)?A\\b|\\bProfessor\\b|Handbook format|\\[(?:under|over)\\s\\d+K\\]|\\(she\\/her\\)|POD\\sFirst\\s)|Author:\\s\\\\b\"\n",
    "\n",
    "    person_keys_to_clean = [\"author\", \"production_editor\", \"project_manager\",\"text_design\",\"subtitle\",\"series\",\"binding\"]\n",
    "    for key in person_keys_to_clean:\n",
    "        if key in results and results[key] is not None:\n",
    "            results[key] = re.sub(authors_pattern, \"\", results[key])\n",
    "\n",
    "    return results\n",
    "\n",
    "updated_metadata = metadata_cleanup(results)\n",
    "\n",
    "# print(\"sanity check...\\n\", updated_metadata)\n",
    "\n",
    "# Convert the dictionary to a list of lists (rows) for tabulate\n",
    "data = [[key, value] for key, value in updated_metadata.items()]\n",
    "\n",
    "# Print the dictionary as a table\n",
    "print(tab.tabulate(data, headers=[\"Key\", \"Metadata\"], tablefmt=\"fancy_grid\"))\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
